{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# **Topic modelling**\n","Topic modelling using the Latent Dirichlet Allocation (LDA)\n","\n","## description\n","Topic modelling aims to discover the hidden semantic structures of a large text\n","corpus, with numerous applications such as automatic categorisation of documents,\n","text mining, text information retrieval, to name a few.\n","\n","## implementation\n","\n","following steps to are being followed in implementation:--\n","\n","1. get the sample data\n","2. clean the data\n","3. use LDA on the data \n","4. predict topics inside the document.\n","\n","\n","    The latent Dirichlet allocation (LDA) is a common\n","    method for topic modelling, based\n","    on the assumption that each document in a corpus is\n","    composed by one or more\n","    hidden topics, and each topic is supported by a number of\n","    words. The process is to\n","    find these hidden topics and their supporting words by \n","    maximising the posterior\n","    probability of the whole corpus given the topics and\n","    words.\n","\n"],"metadata":{"id":"mNSF82rOUbgS"}},{"cell_type":"code","source":["pip install pyLDAvis"],"metadata":{"id":"Dz6ac2dBUZTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKmi1fYkXRWj","executionInfo":{"status":"ok","timestamp":1672257350864,"user_tz":0,"elapsed":2313,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}}},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer\n","from gensim import models, corpora\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"FExllgCTXWhI","executionInfo":{"status":"ok","timestamp":1672257350864,"user_tz":0,"elapsed":10,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}}},"source":["documents = [\n","  \"\"\"\n","  Artificial intelligence (AI), sometimes called machine\n","  intelligence, is intelligence demonstrated by machines, unlike\n","  the natural intelligence displayed by humans and animals. Leading\n","  AI textbooks define the field as the study of \"intelligent\n","  agents\": any device that perceives its environment and takes\n","  actions that maximize its chance of successfully achieving its\n","  goals. Colloquially, the term \"artificial intelligence\" is often\n","  used to describe machines (or computers) that mimic \"cognitive\"\n","  functions that humans associate with the human mind, such\n","  as \"learning\" and \"problem solving\".\n","  \"\"\",\n","  \"\"\"\n","  Association football, more commonly known as football or\n","  soccer, is a team sport played with a spherical ball between\n","  two teams of 11 players. It is played by approximately 250\n","  million players in over 200 countries and dependencies, making it\n","  the world's most popular sport. The game is played on a\n","  rectangular field called a pitch with a goal at each end. The\n","  object of the game is to outscore the opposition by moving the\n","  ball beyond the goal line into the opposing goal. The team with\n","  the higher number of goals wins the game.  \n","  \"\"\"\n","]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"chIHYOhwYhAg","executionInfo":{"status":"ok","timestamp":1672257350865,"user_tz":0,"elapsed":9,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}},"outputId":"a3d36e06-41e5-4b70-dc7a-e2a147bf9729","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Clean the data by using stemming and stopwords removal\n","nltk.download('stopwords')\n","stemmer = SnowballStemmer('english')\n","stop_words = stopwords.words('english')\n","texts = [\n","  [stemmer.stem(word) for word in document.lower().split() if word not in stop_words]\n","  for document in documents\n","  ]"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"9xljrygKZVbT","executionInfo":{"status":"ok","timestamp":1672257351330,"user_tz":0,"elapsed":471,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}}},"source":["# Create a dictionary from the words\n","dictionary = corpora.Dictionary(texts)\n","\n","# Create a document-term matrix\n","doc_term_mat = [dictionary.doc2bow(text) for text in texts]\n","\n","# Generate the LDA model \n","num_topics = 2\n","ldamodel = models.ldamodel.LdaModel(doc_term_mat, \n","        num_topics=num_topics, id2word=dictionary, passes=25)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3XG_FXPhMzq","executionInfo":{"status":"ok","timestamp":1672257351330,"user_tz":0,"elapsed":14,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}},"outputId":"e0fdef40-88ab-4ca1-b437-fb6d4323b7ef","colab":{"base_uri":"https://localhost:8080/"}},"source":["num_words = 5\n","for i in range(num_topics):\n","  print(ldamodel.print_topic(i, topn=num_words))\n","\n","print('\\nTop ' + str(num_words) + ' contributing words to each topic:')\n","for item in ldamodel.print_topics(num_topics=num_topics, num_words=num_words):\n","    print('\\nTopic', item[0])\n","    list_of_strings = item[1].split(' + ')\n","    for text in list_of_strings:\n","        details = text.split('*')\n","        print(\"%-12s:%0.2f%%\" %(details[1], 100*float(details[0])))\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0.035*\"human\" + 0.035*\"intellig\" + 0.025*\"machin\" + 0.015*\"call\" + 0.015*\"associ\"\n","0.036*\"goal\" + 0.036*\"play\" + 0.036*\"team\" + 0.026*\"game\" + 0.026*\"ball\"\n","\n","Top 5 contributing words to each topic:\n","\n","Topic 0\n","\"human\"     :3.50%\n","\"intellig\"  :3.50%\n","\"machin\"    :2.50%\n","\"call\"      :1.50%\n","\"associ\"    :1.50%\n","\n","Topic 1\n","\"goal\"      :3.60%\n","\"play\"      :3.60%\n","\"team\"      :3.60%\n","\"game\"      :2.60%\n","\"ball\"      :2.60%\n"]}]},{"cell_type":"code","metadata":{"id":"5ZmJOtjhQ6WX","executionInfo":{"status":"ok","timestamp":1672257518330,"user_tz":0,"elapsed":6,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}},"outputId":"9f509694-04b6-4c71-a5a3-4a2b5bed0f4d","colab":{"base_uri":"https://localhost:8080/"}},"source":["new_docs = [\n","  \"\"\"\n","  footabll, goal is good. i love football.yesterday's game was good.\n","  AI is is eqally intresting as football. we can try to predict game output\n","  using AI algorithms.\n","  \"\"\"\n","]\n","\n","new_texts = [\n","  [stemmer.stem(word) for word in document.lower().split() if word not in stop_words]\n","  for document in new_docs\n","  ]\n","new_doc_term_mat = [dictionary.doc2bow(text) for text in new_texts]\n","\n","vector = ldamodel[new_doc_term_mat]\n","print(vector[0])\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 0.45892093), (1, 0.5410791)]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ljvIvLDKTvAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F5W2v2F0UX6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyLDAvis.gensim_models\n","pyLDAvis.enable_notebook()\n","vis = pyLDAvis.gensim_models.prepare(ldamodel,doc_term_mat,dictionary,mds=\"mmds\",R=5)\n","vis\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":917},"id":"1JE_LvT2TUHT","executionInfo":{"status":"ok","timestamp":1672257531865,"user_tz":0,"elapsed":459,"user":{"displayName":"sunny kumar","userId":"17706325443169451019"}},"outputId":"755a28ad-28e1-4ad5-c99a-2dd5d19e391c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  default_term_info = default_term_info.sort_values(\n"]},{"output_type":"execute_result","data":{"text/plain":["PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n","topic                                                \n","0     -0.022433  0.070815       1        1  50.940799\n","1      0.022433 -0.070815       2        1  49.059201, topic_info=        Term      Freq     Total Category  logprob  loglift\n","63      goal  2.000000  2.000000  Default   5.0000   5.0000\n","77      play  2.000000  2.000000  Default   4.0000   4.0000\n","86      team  2.000000  2.000000  Default   3.0000   3.0000\n","27     human  2.000000  2.000000  Default   2.0000   2.0000\n","28  intellig  2.000000  2.000000  Default   1.0000   1.0000\n","27     human  1.908757  2.177132   Topic1  -3.3425   0.5429\n","28  intellig  1.908741  2.177132   Topic1  -3.3425   0.5429\n","32    machin  1.363334  1.631676   Topic1  -3.6790   0.4948\n","21     devic  0.817927  1.086221   Topic1  -4.1899   0.3908\n","36     mind,  0.817924  1.086221   Topic1  -4.1899   0.3908\n","14      call  0.818121  1.622305   Topic1  -4.1897  -0.0101\n","13    associ  0.818119  1.622305   Topic1  -4.1897  -0.0101\n","63      goal  1.876024  2.149017   Topic2  -3.3221   0.5763\n","77      play  1.876023  2.149017   Topic2  -3.3221   0.5763\n","86      team  1.876022  2.149017   Topic2  -3.3221   0.5763\n","61      game  1.339955  1.612935   Topic2  -3.6587   0.5267\n","53      ball  1.339952  1.612935   Topic2  -3.6587   0.5267, token_table=      Topic      Freq      Term\n","term                           \n","13        1  0.616407    associ\n","13        2  0.616407    associ\n","53        2  0.619988      ball\n","14        1  0.616407      call\n","14        2  0.616407      call\n","21        1  0.920623     devic\n","61        2  0.619988      game\n","63        2  0.930658      goal\n","27        1  0.918640     human\n","28        1  0.918640  intellig\n","32        1  0.612867    machin\n","36        1  0.920623     mind,\n","77        2  0.930658      play\n","86        2  0.930658      team, R=5, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"],"text/html":["\n","<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n","\n","\n","<div id=\"ldavis_el1031401386322710084243785773\"></div>\n","<script type=\"text/javascript\">\n","\n","var ldavis_el1031401386322710084243785773_data = {\"mdsDat\": {\"x\": [-0.022432814038971082, 0.022432814038971082], \"y\": [0.07081475431730558, -0.07081475431730558], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [50.940798784989525, 49.059201215010475]}, \"tinfo\": {\"Term\": [\"goal\", \"play\", \"team\", \"human\", \"intellig\", \"human\", \"intellig\", \"machin\", \"devic\", \"mind,\", \"call\", \"associ\", \"goal\", \"play\", \"team\", \"game\", \"ball\"], \"Freq\": [2.0, 2.0, 2.0, 2.0, 2.0, 1.9087567537819452, 1.9087414659699142, 1.3633340874231483, 0.8179266082986715, 0.8179240938559031, 0.8181207232803791, 0.8181190134592967, 1.8760243208079632, 1.876023158455837, 1.876021608653002, 1.3399550754667306, 1.3399519758610607], \"Total\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.177132260429256, 2.1771318652538425, 1.6316762733095063, 1.0862207260814747, 1.086220705852644, 1.622305229470987, 1.6223050694527394, 2.1490165172445734, 2.149016788124825, 2.149016596121085, 1.612935303155764, 1.6129351957369884], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [5.0, 4.0, 3.0, 2.0, 1.0, -3.3425, -3.3425, -3.679, -4.1899, -4.1899, -4.1897, -4.1897, -3.3221, -3.3221, -3.3221, -3.6587, -3.6587], \"loglift\": [5.0, 4.0, 3.0, 2.0, 1.0, 0.5429, 0.5429, 0.4948, 0.3908, 0.3908, -0.0101, -0.0101, 0.5763, 0.5763, 0.5763, 0.5267, 0.5267]}, \"token.table\": {\"Topic\": [1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2], \"Freq\": [0.6164068761354085, 0.6164068761354085, 0.6199877110022862, 0.6164068153352913, 0.6164068153352913, 0.920623199308197, 0.6199876697121486, 0.9306582727267078, 0.9186396418588132, 0.9186398086028703, 0.6128666674619923, 0.9206232164530836, 0.9306581554186679, 0.9306582385682569], \"Term\": [\"associ\", \"associ\", \"ball\", \"call\", \"call\", \"devic\", \"game\", \"goal\", \"human\", \"intellig\", \"machin\", \"mind,\", \"play\", \"team\"]}, \"R\": 5, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n","\n","function LDAvis_load_lib(url, callback){\n","  var s = document.createElement('script');\n","  s.src = url;\n","  s.async = true;\n","  s.onreadystatechange = s.onload = callback;\n","  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n","  document.getElementsByTagName(\"head\")[0].appendChild(s);\n","}\n","\n","if(typeof(LDAvis) !== \"undefined\"){\n","   // already loaded: just create the visualization\n","   !function(LDAvis){\n","       new LDAvis(\"#\" + \"ldavis_el1031401386322710084243785773\", ldavis_el1031401386322710084243785773_data);\n","   }(LDAvis);\n","}else if(typeof define === \"function\" && define.amd){\n","   // require.js is available: use it to load d3/LDAvis\n","   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n","   require([\"d3\"], function(d3){\n","      window.d3 = d3;\n","      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","        new LDAvis(\"#\" + \"ldavis_el1031401386322710084243785773\", ldavis_el1031401386322710084243785773_data);\n","      });\n","    });\n","}else{\n","    // require.js not available: dynamically load d3 & LDAvis\n","    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n","         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","                 new LDAvis(\"#\" + \"ldavis_el1031401386322710084243785773\", ldavis_el1031401386322710084243785773_data);\n","            })\n","         });\n","}\n","</script>"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["##**Discussion**\n","\n"," * LDA is a really effective way to to get number of topic inside a big document.\n","\n","* It is also important to remove the stop words from the documents.\n","Depending on the language we use stop words package to remove it. Here we have used SnowballStemmer for the stop words.\n","Also, reducing words to its base form, gives better output.\n","\n","\n","    eg. reduce, reduces , reducing, reduced --> reduce\n","    here all form are reduced to a simpler form \"reduce\".\n","\n","\n"," * also once a LDA model is ready, we can pass new document \n"," to it and can get the probability based result, based on the topic.\n","\n","\n","    eg: we can get with what probability,new document \n","    belongs to already defined category.\n","\n","    * sample result of new doc being passed:--\n","              [(0, 0.45892093), (1, 0.5410791)]\n","                * for topic o probability is 45%\n","                * and for topic 1 probaility is 54%\n","\n"],"metadata":{"id":"ZUbeWRY3a6v5"}}]}